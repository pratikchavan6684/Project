{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ptVP06OuRxFC",
    "outputId": "d6025f4e-7d57-4691-8404-058e8c15cee3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\dell\\anaconda\\lib\\site-packages (3.2.1)\n",
      "Requirement already satisfied: py4j==0.10.9.3 in c:\\users\\dell\\anaconda\\lib\\site-packages (from pyspark) (0.10.9.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Dl4-diAJSJFL"
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import isnan,when,mean,count,col,desc,year,quarter,when,lit,concat,avg,countDistinct\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"P2P_Lending\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ynwQEQRSNkC",
    "outputId": "af9364da-29a0-4eaf-e790-3d571170961d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- member_id: integer (nullable = true)\n",
      " |-- loan_amnt: integer (nullable = true)\n",
      " |-- funded_amnt: integer (nullable = true)\n",
      " |-- funded_amnt_inv: double (nullable = true)\n",
      " |-- term: string (nullable = true)\n",
      " |-- int_rate: string (nullable = true)\n",
      " |-- installment: double (nullable = true)\n",
      " |-- grade: string (nullable = true)\n",
      " |-- sub_grade: string (nullable = true)\n",
      " |-- emp_title: string (nullable = true)\n",
      " |-- emp_length: string (nullable = true)\n",
      " |-- home_ownership: string (nullable = true)\n",
      " |-- annual_inc: double (nullable = true)\n",
      " |-- verification_status: string (nullable = true)\n",
      " |-- issue_d: string (nullable = true)\n",
      " |-- loan_status: string (nullable = true)\n",
      " |-- pymnt_plan: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- desc: string (nullable = true)\n",
      " |-- purpose: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- zip_code: string (nullable = true)\n",
      " |-- addr_state: string (nullable = true)\n",
      " |-- dti: string (nullable = true)\n",
      " |-- delinq_2yrs: string (nullable = true)\n",
      " |-- earliest_cr_line: string (nullable = true)\n",
      " |-- fico_range_low: string (nullable = true)\n",
      " |-- fico_range_high: string (nullable = true)\n",
      " |-- inq_last_6mths: string (nullable = true)\n",
      " |-- mths_since_last_delinq: string (nullable = true)\n",
      " |-- mths_since_last_record: string (nullable = true)\n",
      " |-- open_acc: string (nullable = true)\n",
      " |-- pub_rec: string (nullable = true)\n",
      " |-- revol_bal: string (nullable = true)\n",
      " |-- revol_util: string (nullable = true)\n",
      " |-- total_acc: string (nullable = true)\n",
      " |-- initial_list_status: string (nullable = true)\n",
      " |-- out_prncp: string (nullable = true)\n",
      " |-- out_prncp_inv: string (nullable = true)\n",
      " |-- total_pymnt: string (nullable = true)\n",
      " |-- total_pymnt_inv: string (nullable = true)\n",
      " |-- total_rec_prncp: string (nullable = true)\n",
      " |-- total_rec_int: string (nullable = true)\n",
      " |-- total_rec_late_fee: string (nullable = true)\n",
      " |-- recoveries: string (nullable = true)\n",
      " |-- collection_recovery_fee: string (nullable = true)\n",
      " |-- last_pymnt_d: string (nullable = true)\n",
      " |-- last_pymnt_amnt: string (nullable = true)\n",
      " |-- next_pymnt_d: string (nullable = true)\n",
      " |-- last_credit_pull_d: string (nullable = true)\n",
      " |-- last_fico_range_high: string (nullable = true)\n",
      " |-- last_fico_range_low: string (nullable = true)\n",
      " |-- collections_12_mths_ex_med: string (nullable = true)\n",
      " |-- mths_since_last_major_derog: string (nullable = true)\n",
      " |-- policy_code: string (nullable = true)\n",
      " |-- application_type: string (nullable = true)\n",
      " |-- annual_inc_joint: string (nullable = true)\n",
      " |-- dti_joint: string (nullable = true)\n",
      " |-- verification_status_joint: string (nullable = true)\n",
      " |-- acc_now_delinq: string (nullable = true)\n",
      " |-- tot_coll_amt: string (nullable = true)\n",
      " |-- tot_cur_bal: string (nullable = true)\n",
      " |-- open_acc_6m: string (nullable = true)\n",
      " |-- open_il_6m: string (nullable = true)\n",
      " |-- open_il_12m: string (nullable = true)\n",
      " |-- open_il_24m: string (nullable = true)\n",
      " |-- mths_since_rcnt_il: string (nullable = true)\n",
      " |-- total_bal_il: string (nullable = true)\n",
      " |-- il_util: string (nullable = true)\n",
      " |-- open_rv_12m: string (nullable = true)\n",
      " |-- open_rv_24m: string (nullable = true)\n",
      " |-- max_bal_bc: string (nullable = true)\n",
      " |-- all_util: string (nullable = true)\n",
      " |-- total_rev_hi_lim: string (nullable = true)\n",
      " |-- inq_fi: string (nullable = true)\n",
      " |-- total_cu_tl: string (nullable = true)\n",
      " |-- inq_last_12m: integer (nullable = true)\n",
      " |-- acc_open_past_24mths: integer (nullable = true)\n",
      " |-- avg_cur_bal: string (nullable = true)\n",
      " |-- bc_open_to_buy: integer (nullable = true)\n",
      " |-- bc_util: string (nullable = true)\n",
      " |-- chargeoff_within_12_mths: integer (nullable = true)\n",
      " |-- delinq_amnt: integer (nullable = true)\n",
      " |-- mo_sin_old_il_acct: integer (nullable = true)\n",
      " |-- mo_sin_old_rev_tl_op: integer (nullable = true)\n",
      " |-- mo_sin_rcnt_rev_tl_op: integer (nullable = true)\n",
      " |-- mo_sin_rcnt_tl: integer (nullable = true)\n",
      " |-- mort_acc: integer (nullable = true)\n",
      " |-- mths_since_recent_bc: integer (nullable = true)\n",
      " |-- mths_since_recent_bc_dlq: integer (nullable = true)\n",
      " |-- mths_since_recent_inq: integer (nullable = true)\n",
      " |-- mths_since_recent_revol_delinq: integer (nullable = true)\n",
      " |-- num_accts_ever_120_pd: integer (nullable = true)\n",
      " |-- num_actv_bc_tl: integer (nullable = true)\n",
      " |-- num_actv_rev_tl: integer (nullable = true)\n",
      " |-- num_bc_sats: integer (nullable = true)\n",
      " |-- num_bc_tl: integer (nullable = true)\n",
      " |-- num_il_tl: integer (nullable = true)\n",
      " |-- num_op_rev_tl: integer (nullable = true)\n",
      " |-- num_rev_accts: integer (nullable = true)\n",
      " |-- num_rev_tl_bal_gt_0: integer (nullable = true)\n",
      " |-- num_sats: integer (nullable = true)\n",
      " |-- num_tl_120dpd_2m: integer (nullable = true)\n",
      " |-- num_tl_30dpd: string (nullable = true)\n",
      " |-- num_tl_90g_dpd_24m: integer (nullable = true)\n",
      " |-- num_tl_op_past_12m: integer (nullable = true)\n",
      " |-- pct_tl_nvr_dlq: integer (nullable = true)\n",
      " |-- percent_bc_gt_75: integer (nullable = true)\n",
      " |-- pub_rec_bankruptcies: integer (nullable = true)\n",
      " |-- tax_liens: integer (nullable = true)\n",
      " |-- tot_hi_cred_lim: integer (nullable = true)\n",
      " |-- total_bal_ex_mort: integer (nullable = true)\n",
      " |-- total_bc_limit: integer (nullable = true)\n",
      " |-- total_il_high_credit_limit: integer (nullable = true)\n",
      "\n",
      "Total No of columns -  115\n",
      "Total No of rows -  42542\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"csv\")\\\n",
    "    .option(\"inferSchema\",True)\\\n",
    "    .option(\"header\",True)\\\n",
    "    .option(\"sep\",\",\")\\\n",
    "    .load(\"lending_club_loans.csv\")\n",
    "\n",
    "\n",
    "df.printSchema()\n",
    "\n",
    "dfRows = df.count()\n",
    "print(\"Total No of columns - \", len(df.columns))\n",
    "print(\"Total No of rows - \", dfRows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNWTHmYOTAQJ"
   },
   "source": [
    "# 1. Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1 Cleaning the columns according to requirement**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Removing all the columns which has more than 50% of the data empty***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t9xxCeJuTDp6",
    "outputId": "ff939acb-562d-4364-d4a3-6ad162dd588c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loan Observations -  42542\n",
      "Total No of columns -  115\n"
     ]
    }
   ],
   "source": [
    "# Find the Feature columns which has more than 50% empty data\n",
    "\n",
    "def findMissingValueCols(df):\n",
    "    \n",
    "    missingValueColumns = []\n",
    "    for column in df.columns:\n",
    "        nullRows = df.where(col(column).isNull()).count()\n",
    "        \n",
    "        if nullRows > dfRows*0.5 : # i.e. if ALL values are NULL\n",
    "            missingValueColumns.append(column)\n",
    "    return missingValueColumns\n",
    "\n",
    "missingValueColList = findMissingValueCols(df)\n",
    "\n",
    "print(\"Total Loan Observations - \", df.count())\n",
    "print(\"Total No of columns - \", len(df.columns))\n",
    "#df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kx7qx2DVTJCS",
    "outputId": "2682736c-f785-4da8-e57a-069d320d8bb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total No of columns -  58\n",
      "Total Loan Observations -  42534\n",
      "Count the no rows :42534\n",
      "Count the no of distinct rows:42534\n"
     ]
    }
   ],
   "source": [
    "# 1. Removing all the features which has more than 50% of the data empty \n",
    "\n",
    "df = df.drop(*missingValueColList)\n",
    "\n",
    "print(\"Total No of columns - \", len(df.columns))\n",
    "\n",
    "# 2. Removing all loan observations which has more than 50% of the data empty \n",
    "\n",
    "df = df.dropna(thresh=29) \n",
    "\n",
    "print(\"Total Loan Observations - \", df.count())\n",
    "\n",
    "# 3. Cheking for duplicates and removing them\n",
    "\n",
    "print(\"Count the no rows :{0}\".format(df.count()))\n",
    "print(\"Count the no of distinct rows:{0}\".format(df.distinct().count()))\n",
    "\n",
    "# As we can see there are no duplicates in our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0jYHRiw-T1_b"
   },
   "source": [
    "***Removing those columns having 90% same value***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "4svIBGwzT7fP"
   },
   "outputs": [],
   "source": [
    "num_rows = df.count()\n",
    "threshold = 0.9  # 90% threshold for same values\n",
    "\n",
    "# Iterate over the columns and calculate the percentage of the most common value\n",
    "for col_name in df.columns:\n",
    "    mode_count = df.groupBy(col_name).agg(count(\"*\").alias(\"count\")).orderBy(col(\"count\").desc()).collect()[0][\"count\"]\n",
    "    pct_mode = float(mode_count) / num_rows\n",
    "    #print(f\"{col_name} - mode count: {pct_mode:.2f}\")\n",
    "\n",
    "    # Drop columns with a high percentage of the most common value\n",
    "    if pct_mode > threshold:\n",
    "        df = df.drop(col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oyxnYxyVUOls",
    "outputId": "bc40d1f7-3773-48ec-dc97-2c7e16475f51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total No of columns -  44\n",
      "['id', 'member_id', 'loan_amnt', 'funded_amnt', 'funded_amnt_inv', 'term', 'int_rate', 'installment', 'grade', 'sub_grade', 'emp_title', 'emp_length', 'home_ownership', 'annual_inc', 'verification_status', 'issue_d', 'loan_status', 'url', 'desc', 'purpose', 'title', 'zip_code', 'addr_state', 'dti', 'delinq_2yrs', 'earliest_cr_line', 'fico_range_low', 'fico_range_high', 'inq_last_6mths', 'open_acc', 'revol_bal', 'revol_util', 'total_acc', 'total_pymnt', 'total_pymnt_inv', 'total_rec_prncp', 'total_rec_int', 'recoveries', 'collection_recovery_fee', 'last_pymnt_d', 'last_pymnt_amnt', 'last_credit_pull_d', 'last_fico_range_high', 'last_fico_range_low']\n"
     ]
    }
   ],
   "source": [
    "print(\"Total No of columns - \", len(df.columns))\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4EocV1dOYk6W"
   },
   "source": [
    "***Removing columns based on some criteria***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "yVmCLJB0TNMZ"
   },
   "outputs": [],
   "source": [
    "#Reading data dictionary in which information regarding each column is given\n",
    "\n",
    "loan_dict=spark.read.csv(\"LCDataDictionary.csv\",header=True)\n",
    "\n",
    "#loan_dict.show()\n",
    "\n",
    "#We will remove the columns based on following criteria:-\n",
    "\n",
    "#leaks information from the future (after the loan has already been funded),\n",
    "#doesn’t affect the borrower’s ability to pay back the loan (e.g. a randomly generated ID value by Lending Club),\n",
    "#is formatted poorly,\n",
    "#requires more data or a lot of pre-processing to turn into useful a feature, or\n",
    "#contains redundant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M4FNIbmKTRR1",
    "outputId": "0cf6d1ed-5558-4ce7-9ec2-a70b2c7d07a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total No of columns -  26\n",
      "['loan_amnt', 'term', 'installment', 'grade', 'emp_length', 'home_ownership', 'annual_inc', 'verification_status', 'issue_d', 'loan_status', 'purpose', 'title', 'addr_state', 'dti', 'delinq_2yrs', 'earliest_cr_line', 'fico_range_low', 'fico_range_high', 'inq_last_6mths', 'open_acc', 'revol_bal', 'revol_util', 'total_acc', 'last_credit_pull_d', 'last_fico_range_high', 'last_fico_range_low']\n"
     ]
    }
   ],
   "source": [
    "# removing those columns which does not give valueable insights to build model\n",
    "\n",
    "df = df.drop('id','member_id','int_rate','emp_title','url','desc','zip_code','sub_grade')\n",
    "\n",
    "# removing those columns which leaks data from the future\n",
    "\n",
    "df = df.drop('funded_amnt','funded_amnt_inv','total_pymnt','total_pymnt_inv','total_rec_prncp','total_rec_int','recoveries','collection_recovery_fee','last_pymnt_d','last_pymnt_amnt')\n",
    "\n",
    "print(\"Total No of columns - \", len(df.columns))\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Investigate date columns and Removing column which are not useful***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxmuLc_QQpUo"
   },
   "source": [
    "'earliest_cr_line': The month the borrower's earliest reported credit line was opened; we do not need ths column for our analysis\n",
    "\n",
    "'last_credit_pull_d': The most recent month LendingClub pulled credit for this loan; we do not need ths column for our analysis.\n",
    "\n",
    "'issue_d': The date which the loan was funded. It means the date investor received full amount of money they need. We don't need this column; also it leak future information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uLKpnnCnQjX0",
    "outputId": "5bf4421a-c972-47fc-9f4b-51c96cfc1088"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total No of columns -  23\n"
     ]
    }
   ],
   "source": [
    "df = df.drop('earliest_cr_line', 'last_credit_pull_d','issue_d')\n",
    "\n",
    "print(\"Total No of columns - \", len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIw07zbcUSZU"
   },
   "source": [
    "***Investigating FICO Score Columns***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eSdqFE2XUUYQ",
    "outputId": "2b51bc29-734f-4888-df8c-09caa7e312a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Total No of columns -  24\n",
      "+------------+---------------+--------------+\n",
      "|fico_average|fico_range_high|fico_range_low|\n",
      "+------------+---------------+--------------+\n",
      "|       737.0|            739|           735|\n",
      "|       742.0|            744|           740|\n",
      "|       737.0|            739|           735|\n",
      "|       692.0|            694|           690|\n",
      "|       697.0|            699|           695|\n",
      "|       732.0|            734|           730|\n",
      "|       692.0|            694|           690|\n",
      "|       662.0|            664|           660|\n",
      "|       677.0|            679|           675|\n",
      "|       727.0|            729|           725|\n",
      "|       697.0|            699|           695|\n",
      "|       677.0|            679|           675|\n",
      "|       712.0|            714|           710|\n",
      "|       707.0|            709|           705|\n",
      "|       722.0|            724|           720|\n",
      "|       667.0|            669|           665|\n",
      "|       672.0|            674|           670|\n",
      "|       762.0|            764|           760|\n",
      "|       687.0|            689|           685|\n",
      "|       757.0|            759|           755|\n",
      "+------------+---------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Total No of columns -  20\n"
     ]
    }
   ],
   "source": [
    "#Let’s get rid of the missing values,\n",
    "\n",
    "print(df.filter(col('fico_range_high').isNull()).count())\n",
    "\n",
    "#As there are no null values let's proceed further\n",
    "#Let's take average of fico_range_low and fico_range_high\n",
    "df = df.withColumn('fico_average', (col('fico_range_high') + col('fico_range_low')) / 2)\n",
    "print(\"Total No of columns - \", len(df.columns))\n",
    "\n",
    "#Let's look at result\n",
    "df.select('fico_average', 'fico_range_high', 'fico_range_low').show()\n",
    "\n",
    "#Now we have got mean value of FICO score which we can use further\n",
    "#Now, we can go ahead and drop fico_range_low, fico_range_high, last_fico_range_low, and last_fico_range_high columns.\n",
    "\n",
    "df = df.drop('fico_range_low', 'fico_range_high','last_fico_range_high', 'last_fico_range_low')\n",
    "print(\"Total No of columns - \", len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPLK5oHPUgGa"
   },
   "source": [
    "**1.2 Converting target columns into binary values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2rfohXhNUklx",
    "outputId": "a34e827a-c211-44ee-b79b-305dca809428"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|         loan_status|count|\n",
      "+--------------------+-----+\n",
      "|          Fully Paid|33586|\n",
      "|     In Grace Period|   16|\n",
      "|         Charged Off| 5652|\n",
      "|  Late (31-120 days)|   12|\n",
      "|             Current|  513|\n",
      "|   Late (16-30 days)|    5|\n",
      "|             Default|    1|\n",
      "|Does not meet the...| 1988|\n",
      "|Does not meet the...|  761|\n",
      "+--------------------+-----+\n",
      "\n",
      "+-----------+-----+\n",
      "|loan_status|count|\n",
      "+-----------+-----+\n",
      "|          1|33586|\n",
      "|          0| 5652|\n",
      "+-----------+-----+\n",
      "\n",
      "Count the no rows :39238\n"
     ]
    }
   ],
   "source": [
    "#Our main goal is predict who will pay off a loan and who will default\n",
    "#loan_status is the only field in the main data set that describes a loan status, so let’s use this column as the target column.\n",
    "\n",
    "#We’ll use the DataFrame method value_counts() to return the frequency of the unique values in the loan_status column.\n",
    "\n",
    "df.groupBy(\"loan_status\").count().show()\n",
    "\n",
    "\n",
    "# Filter the DataFrame\n",
    "df = df.filter(df.loan_status.isin([\"Fully Paid\", \"Charged Off\"]))\n",
    "\n",
    "# Replace loan_status values with 1 and 0\n",
    "df = df.withColumn(\"loan_status\", when(df.loan_status == \"Fully Paid\", 1).otherwise(0))\n",
    "\n",
    "df.groupBy(\"loan_status\").count().show()\n",
    "\n",
    "print(\"Count the no rows :{0}\".format(df.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpzEYTI-Z2FC"
   },
   "source": [
    "**1.3 Dropping missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2GwIhZc3U2fT",
    "outputId": "17f7e475-4972-463d-da4a-a446f3747cd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in each column:\n",
      "{'loan_amnt': 0, 'term': 0, 'installment': 0, 'grade': 0, 'emp_length': 0, 'home_ownership': 0, 'annual_inc': 0, 'verification_status': 0, 'loan_status': 0, 'purpose': 0, 'title': 9, 'addr_state': 0, 'dti': 0, 'delinq_2yrs': 0, 'inq_last_6mths': 0, 'open_acc': 71, 'revol_bal': 46, 'revol_util': 78, 'total_acc': 16, 'fico_average': 191}\n"
     ]
    }
   ],
   "source": [
    "# Create an empty dictionary to store the null counts\n",
    "null_counts = {}\n",
    "\n",
    "# Loop through each column and get the count of null values\n",
    "for c in df.columns:\n",
    "    null_count = df.where(col(c).isNull()).count()\n",
    "    null_counts[c] = null_count\n",
    "\n",
    "# Print the null counts dictionary\n",
    "print(\"Number of null values in each column:\")\n",
    "print(null_counts)\n",
    "\n",
    "#Removing the rows having the null values\n",
    "df = df.na.drop(how=\"any\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TJ3fvF-ZB1p"
   },
   "source": [
    "**1.4 Encoding of Categorical Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_9aGvVRCVBiM",
    "outputId": "703e96cd-9a53-40eb-b515-3cecd6687b9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(term=' 36 months', grade='B', emp_length='10+ years', home_ownership='RENT', verification_status='Verified', purpose='credit_card', title='Computer', addr_state='AZ', dti='27.65', delinq_2yrs='0', inq_last_6mths='1', open_acc='3', revol_bal='13648', revol_util='83.70%', total_acc='9')\n"
     ]
    }
   ],
   "source": [
    "#Investigate Categorical Columns\n",
    "\n",
    "# Filter dataframe columns by datatype 'string'\n",
    "object_columns_df = df.select([col(c).alias(c) for c in df.columns if df.schema[c].dataType == StringType()])\n",
    "\n",
    "# Print first row of the dataframe\n",
    "print(object_columns_df.first())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dTSaW15KSp9i"
   },
   "source": [
    "***Label Encoding : Converting Ordinal categories column to numerical values***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "HE-dtohnVDTr"
   },
   "outputs": [],
   "source": [
    "#cleaning the 'term' and 'revol_util' columns\n",
    "\n",
    "df = df.withColumn(\"term\", regexp_replace(\"term\", \"months\", \"\"))\n",
    "\n",
    "df = df.withColumn(\"revol_util\", regexp_replace(\"revol_util\", \"%\", \"\"))\n",
    "\n",
    "#### Converting Categorical feature \"emp_length\" and \"grade\" to continous feature\n",
    "\n",
    "\n",
    "df = df.withColumn(\"emp_lengthIndex\", when(col(\"emp_length\") == \"< 1 year\", 0)\n",
    "                                           .when(col(\"emp_length\") == \"1 year\", 1)\n",
    "                                           .when(col(\"emp_length\") == \"2 years\", 2)\n",
    "                                           .when(col(\"emp_length\") == \"3 years\", 3)\n",
    "                                           .when(col(\"emp_length\") == \"4 years\", 4)\n",
    "                                           .when(col(\"emp_length\") == \"5 years\", 5)\n",
    "                                           .when(col(\"emp_length\") == \"6 years\", 6)\n",
    "                                           .when(col(\"emp_length\") == \"7 years\", 7)\n",
    "                                           .when(col(\"emp_length\") == \"8 years\", 8)\n",
    "                                           .when(col(\"emp_length\") == \"9 years\", 9)\n",
    "                                           .when(col(\"emp_length\") == \"10+ years\", 10)\n",
    "                                           .otherwise(0))\n",
    "\n",
    "\n",
    "\n",
    "df = df.withColumn(\"grade_Index\", when(col(\"grade\") == \"A\", 1)\n",
    "                                           .when(col(\"grade\") == \"B\", 2)\n",
    "                                           .when(col(\"grade\") == \"C\", 3)\n",
    "                                           .when(col(\"grade\") == \"D\", 4)\n",
    "                                           .when(col(\"grade\") == \"E\", 5)\n",
    "                                           .when(col(\"grade\") == \"F\", 6)\n",
    "                                           .when(col(\"grade\") == \"G\", 7)\n",
    "                                           .otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uEEeE_-jVLad",
    "outputId": "9fe3777a-2f3d-409c-b129-1d6675813199"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(loan_amnt=5000, term=' 36 ', installment=162.87, grade='B', emp_length='10+ years', home_ownership='RENT', annual_inc=24000.0, verification_status='Verified', loan_status=1, purpose='credit_card', title='Computer', addr_state='AZ', dti='27.65', delinq_2yrs='0', inq_last_6mths='1', open_acc='3', revol_bal='13648', revol_util='83.70', total_acc='9', fico_average=737.0, emp_lengthIndex=10, grade_Index=2)\n"
     ]
    }
   ],
   "source": [
    "print(df.first())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vW4cHlg4fQZB"
   },
   "source": [
    "***One Hot Encoding: Converting Nominal categories column to binary vectors*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "akC0XzaIredM"
   },
   "source": [
    "Identify the categorical columns that need to be encoded.\n",
    "Use StringIndexer to convert the categorical columns into numerical indexes.\n",
    "Use OneHotEncoder to convert the numerical indexes into sparse vector representation of binary encoded columns.\n",
    "Use VectorAssembler to combine the encoded columns with other numerical columns in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "QbRdBXaxfV7v"
   },
   "outputs": [],
   "source": [
    "#Applying One-Hot Encoding on Categorical columns\n",
    "\n",
    "\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "\n",
    "nominal_columns = [\"home_ownership\", \"verification_status\", \"purpose\", \"term\"]\n",
    "\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\")    for column in nominal_columns]\n",
    "\n",
    "encoders = [OneHotEncoder(inputCol=column+\"_index\", outputCol=column+\"_encoded\")   for column in nominal_columns]\n",
    "\n",
    "pipeline = Pipeline(stages=indexers + encoders)\n",
    "df = pipeline.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C3F__76HZUYx"
   },
   "source": [
    "***Converting string type columns into double type***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "heH9Y-eON9go"
   },
   "outputs": [],
   "source": [
    "\n",
    "lst=['dti','delinq_2yrs','inq_last_6mths','open_acc','revol_bal','total_acc','revol_util']\n",
    "\n",
    "for col_name in lst:\n",
    "    df = df.withColumn(col_name, col(col_name).cast(\"double\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oI1AbQqXWLt6"
   },
   "source": [
    "**1.5 Data Balancing and Scaling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Data Balancing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vSNE5P7MWRfG",
    "outputId": "1e9da913-ee45-47c9-ecb0-544f12b393a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|loan_status|count|\n",
      "+-----------+-----+\n",
      "|          1|27912|\n",
      "|          0| 5603|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count the number of observations in each class\n",
    "count_charged_off = df.filter(df.loan_status == 0).count()\n",
    "count_fully_paid = df.filter(df.loan_status == 1).count()\n",
    "\n",
    "# Compute the ratio of the class counts\n",
    "ratio = count_charged_off / count_fully_paid\n",
    "\n",
    "# Create a sample of fully paid observations with a fraction of (1-ratio) \n",
    "df_fully_paid = df.filter(df.loan_status == 1).sample(False, 1 - ratio, seed=42)\n",
    "\n",
    "# Create a dataframe of the minority class \n",
    "df_charged_off = df.filter(df.loan_status == 0)\n",
    "\n",
    "# Combine the two dataframes\n",
    "df = df_fully_paid.union(df_charged_off)\n",
    "\n",
    "# Verify the class counts\n",
    "df.groupBy('loan_status').count().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_Quhdc1ZuUr"
   },
   "source": [
    "***Data Scaling***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c17heDgk0Ccg",
    "outputId": "dc3a4dfb-9cd0-40e3-bf1e-4e9f9b191ef4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+-----------+-----+----------+--------------+----------+-------------------+-----------+------------------+--------------------+----------+-----+-----------+--------------+--------+---------+----------+---------+------------+---------------+-----------+--------------------+-------------------------+-------------+----------+----------------------+---------------------------+---------------+-------------+--------------------+--------------------+\n",
      "|loan_amnt|term|installment|grade|emp_length|home_ownership|annual_inc|verification_status|loan_status|           purpose|               title|addr_state|  dti|delinq_2yrs|inq_last_6mths|open_acc|revol_bal|revol_util|total_acc|fico_average|emp_lengthIndex|grade_Index|home_ownership_index|verification_status_index|purpose_index|term_index|home_ownership_encoded|verification_status_encoded|purpose_encoded| term_encoded|            features|     scaled_features|\n",
      "+---------+----+-----------+-----+----------+--------------+----------+-------------------+-----------+------------------+--------------------+----------+-----+-----------+--------------+--------+---------+----------+---------+------------+---------------+-----------+--------------------+-------------------------+-------------+----------+----------------------+---------------------------+---------------+-------------+--------------------+--------------------+\n",
      "|     5000| 36 |     162.87|    B| 10+ years|          RENT|   24000.0|           Verified|          1|       credit_card|            Computer|        AZ|27.65|        0.0|           1.0|     3.0|  13648.0|      83.7|      9.0|       737.0|             10|          2|                 0.0|                      1.0|          1.0|       0.0|         (4,[0],[1.0])|              (2,[1],[1.0])| (17,[1],[1.0])|(1,[0],[1.0])|[5000.0,162.87,24...|[-0.8326716949953...|\n",
      "|     2400| 36 |      84.33|    C| 10+ years|          RENT|   12252.0|       Not Verified|          1|    small_business|real estate business|        IL| 8.72|        0.0|           2.0|     2.0|   2956.0|      98.5|     10.0|       737.0|             10|          3|                 0.0|                      0.0|          5.0|       0.0|         (4,[0],[1.0])|              (2,[0],[1.0])| (17,[5],[1.0])|(1,[0],[1.0])|[2400.0,84.33,122...|[-1.1834298455685...|\n",
      "|     5000| 36 |     156.46|    A|   3 years|          RENT|   36000.0|    Source Verified|          1|           wedding|My wedding loan I...|        AZ| 11.2|        0.0|           3.0|     9.0|   7963.0|      28.3|     12.0|       732.0|              3|          1|                 0.0|                      2.0|          7.0|       0.0|         (4,[0],[1.0])|                  (2,[],[])| (17,[7],[1.0])|(1,[0],[1.0])|[5000.0,156.46,36...|[-0.8326716949953...|\n",
      "|     7000| 60 |     170.08|    C|   8 years|          RENT|   47004.0|       Not Verified|          1|debt_consolidation|                Loan|        NC|23.51|        0.0|           1.0|     7.0|  17726.0|      85.6|     11.0|       692.0|              8|          3|                 0.0|                      0.0|          0.0|       1.0|         (4,[0],[1.0])|              (2,[0],[1.0])| (17,[0],[1.0])|    (1,[],[])|[7000.0,170.08,47...|[-0.5628577330159...|\n",
      "|     3000| 36 |     109.43|    E|   9 years|          RENT|   48000.0|    Source Verified|          1|               car|     Car Downpayment|        CA| 5.35|        0.0|           2.0|     4.0|   8221.0|      87.5|      4.0|       662.0|              9|          5|                 0.0|                      2.0|          6.0|       0.0|         (4,[0],[1.0])|                  (2,[],[])| (17,[6],[1.0])|(1,[0],[1.0])|[3000.0,109.43,48...|[-1.1024856569747...|\n",
      "+---------+----+-----------+-----+----------+--------------+----------+-------------------+-----------+------------------+--------------------+----------+-----+-----------+--------------+--------+---------+----------+---------+------------+---------------+-----------+--------------------+-------------------------+-------------+----------+----------------------+---------------------------+---------------+-------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# select the columns to normalize\n",
    "cols_to_norm = ['loan_amnt', 'installment', 'annual_inc','dti','delinq_2yrs','inq_last_6mths','open_acc','revol_bal','total_acc','revol_util','fico_average']\n",
    "\n",
    "# assemble the features into a vector\n",
    "assembler = VectorAssembler(inputCols=cols_to_norm, outputCol='features',handleInvalid='skip')\n",
    "df = assembler.transform(df)\n",
    "\n",
    "# initialize the scaler\n",
    "scaler = StandardScaler(inputCol='features', outputCol='scaled_features',withMean=True,withStd=True)\n",
    "\n",
    "# fit and transform the data\n",
    "df = scaler.fit(df).transform(df)\n",
    "\n",
    "# show the first 5 rows of the scaled data\n",
    "df.show(5)\n",
    "\n",
    "# droping features cloumn\n",
    "df = df.drop('features') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mvXL8gKjhrSY",
    "outputId": "f21c1688-620d-474d-e491-fdb3d14132ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(loan_amnt=5000, term=' 36 ', installment=162.87, grade='B', emp_length='10+ years', home_ownership='RENT', annual_inc=24000.0, verification_status='Verified', loan_status=1, purpose='credit_card', title='Computer', addr_state='AZ', dti=27.65, delinq_2yrs=0.0, inq_last_6mths=1.0, open_acc=3.0, revol_bal=13648.0, revol_util=83.7, total_acc=9.0, fico_average=737.0, emp_lengthIndex=10, grade_Index=2, home_ownership_index=0.0, verification_status_index=1.0, purpose_index=1.0, term_index=0.0, home_ownership_encoded=SparseVector(4, {0: 1.0}), verification_status_encoded=SparseVector(2, {1: 1.0}), purpose_encoded=SparseVector(17, {1: 1.0}), term_encoded=SparseVector(1, {0: 1.0}), scaled_features=DenseVector([-0.8327, -0.7718, -0.7123, 2.1471, -0.2982, 0.1144, -1.4294, 0.0168, -1.1496, 1.2277, 0.5654]))\n"
     ]
    }
   ],
   "source": [
    "print(df.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "fagGGxLeht1u"
   },
   "outputs": [],
   "source": [
    "#dropping the original columns after one-hot encoding\n",
    "df = df.drop('addr_state','title','grade','sub_grade','emp_length',\"home_ownership\", \"verification_status\", \"purpose\", \"term\",\"home_ownership_index\",\"purpose_index\",\"verification_status_index\",\"purpose_index\",\"term_index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ncYi-YVclr4Z",
    "outputId": "8b0fa29f-806e-46e8-c279-661bf1d999b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- loan_amnt: integer (nullable = true)\n",
      " |-- installment: double (nullable = true)\n",
      " |-- annual_inc: double (nullable = true)\n",
      " |-- loan_status: integer (nullable = false)\n",
      " |-- dti: double (nullable = true)\n",
      " |-- delinq_2yrs: double (nullable = true)\n",
      " |-- inq_last_6mths: double (nullable = true)\n",
      " |-- open_acc: double (nullable = true)\n",
      " |-- revol_bal: double (nullable = true)\n",
      " |-- revol_util: double (nullable = true)\n",
      " |-- total_acc: double (nullable = true)\n",
      " |-- fico_average: double (nullable = true)\n",
      " |-- emp_lengthIndex: integer (nullable = false)\n",
      " |-- grade_Index: integer (nullable = false)\n",
      " |-- home_ownership_encoded: vector (nullable = true)\n",
      " |-- verification_status_encoded: vector (nullable = true)\n",
      " |-- purpose_encoded: vector (nullable = true)\n",
      " |-- term_encoded: vector (nullable = true)\n",
      " |-- scaled_features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#checking if there are any string type columns left\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fiBHEP0nH7x"
   },
   "source": [
    "**1.6 Vector Assembling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "H7RpMNtTECNg"
   },
   "outputs": [],
   "source": [
    "col_list=['emp_lengthIndex','grade_Index','home_ownership_encoded','verification_status_encoded','purpose_encoded','term_encoded','scaled_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "kG6SMhlOmygw"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# set the input and output column names\n",
    "#assembler = VectorAssembler(inputCols=[ *col_list ], outputCol=\"features\",handleInvalid = \"keep\")\n",
    "assembler = VectorAssembler(inputCols=col_list, outputCol=\"features\",handleInvalid='skip')\n",
    "\n",
    "df = assembler.transform( df)\n",
    "\n",
    "\n",
    "df = df.select(\"loan_status\", \"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nO4tkbgJ4yOe"
   },
   "source": [
    "**2.1 Logistic Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iVa-e9Bw5xKF",
    "outputId": "98a2ada1-0c48-4c8b-9167-3ac2dc8207ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Area Under ROC: 0.6881617663835148\n",
      "Test Area Under ROC: 0.6792552435554896\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression( labelCol=\"loan_status\",featuresCol=\"features\", maxIter=10, regParam=0.8)\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "(trainingData, testData) = df.randomSplit([0.7, 0.3], seed=100)\n",
    "\n",
    "# Train the model on the training data\n",
    "model =  lr.fit(trainingData)\n",
    "\n",
    "# Use the model to make predictions on the training data\n",
    "predictions_train = model.transform(trainingData)\n",
    "\n",
    "# Use the model to make predictions on the testing data\n",
    "predictions_test = model.transform(testData)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"loan_status\")\n",
    "print(\"Train Area Under ROC: \" + str(evaluator.evaluate(predictions_train)))\n",
    "print(\"Test Area Under ROC: \" + str(evaluator.evaluate(predictions_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ym4AplYIj0xq"
   },
   "source": [
    "**2.2 Decision Tree Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tEPABiViECNp",
    "outputId": "eafefc9f-4011-477b-ce55-3bc5e1d3dfa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6302612907396437\n",
      "0.6214427679354979\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "# Define the Decision Tree Classifier model\n",
    "dt = DecisionTreeClassifier(labelCol=\"loan_status\", featuresCol=\"features\")\n",
    "\n",
    "# Train the model on the training data\n",
    "model = dt.fit(trainingData)\n",
    "\n",
    "# Use the model to make predictions on the training data\n",
    "predictions_train = model.transform(trainingData)\n",
    "\n",
    "# Use the model to make predictions on the testing data\n",
    "predictions_test = model.transform(testData)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"loan_status\")\n",
    "accuracy_train = evaluator.evaluate(predictions_train)\n",
    "\n",
    "accuracy_test = evaluator.evaluate(predictions_test)\n",
    "\n",
    "print(accuracy_train)\n",
    "print(accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYCiZiiiECNq"
   },
   "source": [
    "**2.3 Random Forest Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5QQ_3e9aECNq",
    "outputId": "c1296f98-cbf5-4012-c5db-d3aee8a9a434"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7017075528428357\n",
      "0.6831466618348274\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# Define the Random Forest Classifier model\n",
    "rf = RandomForestClassifier(labelCol=\"loan_status\", featuresCol=\"features\")\n",
    "\n",
    "# Train the model on the training data\n",
    "model = rf.fit(trainingData)\n",
    "\n",
    "# Use the model to make predictions on the testing data\n",
    "predictions_train = model.transform(trainingData)\n",
    "\n",
    "# Use the model to make predictions on the testing data\n",
    "predictions_test = model.transform(testData)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"loan_status\")\n",
    "accuracy_train = evaluator.evaluate(predictions_train)\n",
    "accuracy_test = evaluator.evaluate(predictions_test)\n",
    "\n",
    "print(accuracy_train)\n",
    "print(accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CzE7_3tgECNr"
   },
   "source": [
    "**2.4 Gradient Boosting Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CqLbHjUGECNr",
    "outputId": "6077007f-2612-4b11-bb65-f8c62c216a27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7300635865860928\n",
      "0.6856434206555232\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "# Define the Gradient Boosting Machine Classifier model\n",
    "gbt = GBTClassifier(labelCol=\"loan_status\", featuresCol=\"features\", maxIter=10)\n",
    "\n",
    "# Train the model on the training data\n",
    "model = gbt.fit(trainingData)\n",
    "\n",
    "# Use the model to make predictions on the testing data\n",
    "predictions_train = model.transform(trainingData)\n",
    "\n",
    "# Use the model to make predictions on the testing data\n",
    "predictions_test = model.transform(testData)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"loan_status\")\n",
    "accuracy_train = evaluator.evaluate(predictions_train)\n",
    "accuracy_test = evaluator.evaluate(predictions_test)\n",
    "\n",
    "print(accuracy_train)\n",
    "print(accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-SQhjzMdbccQ"
   },
   "source": [
    "**2.5 Support Vector Machine Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Goi1INOUbUdX",
    "outputId": "c35bf3bb-f715-4ce8-baec-a3b1c8767116"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6486091409536533\n",
      "0.6472642099162444\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "\n",
    "# Define the Support Vector Machine Classifier model\n",
    "svm = LinearSVC(labelCol=\"loan_status\", featuresCol=\"features\", maxIter=10, regParam=0.1)\n",
    "\n",
    "# Train the model on the training data\n",
    "model = svm.fit(trainingData)\n",
    "\n",
    "# Use the model to make predictions on the testing data\n",
    "predictions_train = model.transform(trainingData)\n",
    "\n",
    "# Use the model to make predictions on the testing data\n",
    "predictions_test = model.transform(testData)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"loan_status\")\n",
    "accuracy_train = evaluator.evaluate(predictions_train)\n",
    "accuracy_test = evaluator.evaluate(predictions_test)\n",
    "\n",
    "print(accuracy_train)\n",
    "print(accuracy_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
